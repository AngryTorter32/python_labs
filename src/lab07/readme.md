## –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è_07</h1>
### –ó–∞–¥–∞–Ω–∏–µ –ê
```python
import pytest
from src.lib.text import normalize, tokenize, count_freq, top_n

@pytest.mark.parametrize(
    "source, casefold, yo2e, expected",
    [
        # –±–∞–∑–æ–≤—ã–µ —Å–ª—É—á–∞–∏ —Å casefold=True –∏ yo2e=True
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", True, True, "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", True, True, "–µ–∂–∏–∫, –µ–ª–∫–∞"),
        ("Hello\r\nWorld", True, True, "hello world"),
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", True, True, "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        # –±–µ–∑ casefold
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", False, True, "–ü—Ä–ò–≤–ï—Ç –ú–ò—Ä"),
        ("Hello\r\nWorld", False, True, "Hello World"),
        # –±–µ–∑ –∑–∞–º–µ–Ω—ã —ë –Ω–∞ –µ
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", True, False, "—ë–∂–∏–∫, —ë–ª–∫–∞"),
        ("–ú–æ–π –Å–∂", True, False, "–º–æ–π —ë–∂"),
        # –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
        ("", True, True, ""),
        ("   ", True, True, ""),
        ("\n\t\r\b", True, True, ""),
        # –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        ("–ü–†–ò–í–ï–¢\n–º–∏—Ä\t", False, False, "–ü–†–ò–í–ï–¢ –º–∏—Ä"),
        ("–Å–ñ–ò–ö\n—ë–ª–∫–∞", False, True, "–ï–ñ–ò–ö –µ–ª–∫–∞"),
    ],
)
def test_normalize_basic(source, casefold, yo2e, expected):
    assert normalize(source, casefold, yo2e) == expected

@pytest.mark.parametrize(
    "source, expected",
    [
        # –±–∞–∑–æ–≤—ã–µ —Å–ª—É—á–∞–∏
        ("–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä!", ["–ü—Ä–∏–≤–µ—Ç", "–º–∏—Ä"]),
        ("Hello world!", ["Hello", "world"]),
        # –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
        ("", []),
        ("!#$%", []),
        ("   ", []),
        # —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        ("–í–æ–ø—Ä–æ—Å? –û—Ç–≤–µ—Ç! –ò—Ç–æ–≥:", ["–í–æ–ø—Ä–æ—Å", "–û—Ç–≤–µ—Ç", "–ò—Ç–æ–≥"]),
        ("–¶–µ–Ω–∞: $100 & 50% —Å–∫–∏–¥–∫–∞", ["–¶–µ–Ω–∞", "100", "50", "—Å–∫–∏–¥–∫–∞"]),
        # —ç–º–æ–¥–∑–∏ –∏ —Ç–∏—Ä–µ
        ("–Ø üòÄ —Å—á–∞—Å—Ç–ª–∏–≤!", ["–Ø", "—Å—á–∞—Å—Ç–ª–∏–≤"]),
        ("–î–ª–∏–Ω–Ω–æ–µ ‚Äî –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ —Ç–∏—Ä–µ", ["–î–ª–∏–Ω–Ω–æ–µ", "–æ—á–µ–Ω—å", "–¥–ª–∏–Ω–Ω–æ–µ", "—Ç–∏—Ä–µ"]),
        # –º–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
        ("–°–ª–æ–≤–æ,,, —Å–ª–æ–≤–æ!!! —Å–ª–æ–≤–æ???", ["–°–ª–æ–≤–æ", "—Å–ª–æ–≤–æ", "—Å–ª–æ–≤–æ"]),
    ],
)
def test_tokenize_basic(source, expected):
    assert tokenize(source) == expected

@pytest.mark.parametrize(
    "tokens, expected",
    [
        # –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è count_freq
        (
            ["—è", "–ª—é–±–ª—é", "python", "—è", "–ª—é–±–ª—é", "–∫–æ–¥"],
            {"—è": 2, "–∫–æ–¥": 1, "–ª—é–±–ª—é": 2, "python": 1},
        ),
        (["test"], {"test": 1}),
        (["word", "word", "word"], {"word": 3}),
    ],
)
def test_count_f_basic(tokens, expected):
    assert count_freq(tokens) == expected

@pytest.mark.parametrize(
    "tokens, n, expected",
    [
        # –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è top_n
        (
            ["—è", "–ª—é–±–ª—é", "python", "—è", "–ª—é–±–ª—é", "–∫–æ–¥", "python", "python"],
            2,
            [("python", 3), ("–ª—é–±–ª—é", 2)],
        ),
        (["a", "b", "a"], 5, [("a", 2), ("b", 1)]),
        ([], 5, []),
        # —Å–ª—É—á–∞–π —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —á–∞—Å—Ç–æ—Ç–æ–π, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        (
            ["—è–±–ª–æ–∫–æ", "–∞–ø–µ–ª—å—Å–∏–Ω", "—è–±–ª–æ–∫–æ", "–∞–ø–µ–ª—å—Å–∏–Ω", "–±–∞–Ω–∞–Ω", "–±–∞–Ω–∞–Ω"],
            3,
            [("–∞–ø–µ–ª—å—Å–∏–Ω", 2), ("–±–∞–Ω–∞–Ω", 2), ("—è–±–ª–æ–∫–æ", 2)],
        ),
        (
            ["z", "a", "b", "z", "a", "c", "b", "a", "d"],
            4,
            [("a", 3), ("b", 2), ("z", 2), ("c", 1)],
        ),
    ],
)
def test_top_n_basic(tokens, n, expected):
    assert top_n(tokens, n) == expected
```
–í –Ω–∞—á–∞–ª–µ —Ä–∞–±–æ—Ç—ã —è —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é pytest –ø—Ä–∏ –ø–æ–º–æ—â–∏ pip, –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –ø—Ä–æ–≤–µ—Ä—è—é —É—Å—Ç–∞–Ω–æ–≤–∫—É black. –ó–∞—Ç–µ–º, –ø—Ä–∏ –ø–æ–º–æ—â–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏–∏, —è —Å–æ–∑–¥–∞—é –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ—É–Ω–∫—Ü–∏–∏. –î–ª—è normalize –º–Ω–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—ã–ª–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ö–∞–Ω–∏–∑–º—ã –∑–∞–º–µ–Ω—ã —ë –Ω–∞ –µ, —Å—Ö–ª–æ–ø—ã–≤–∞–Ω–∏—è –ø—Ä–æ–±–µ–ª–æ–≤, —Ä–µ–∞–∫—Ü–∏—é —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∞ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –∏ —Å—Ç—Ä–æ–∫–∏, —Å–æ—Å—Ç–æ—è—â–∏–µ –∏–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤. –î–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ tokenize, –ø–æ—Å–ª–µ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Ä–∞–±–æ—Ç—ã, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—ã–ª–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ª—É—á–∞–∏ —Å–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º —Å–∏–º–≤–æ–ª–æ–≤ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ –∏ —ç–º–æ–¥–∑–∏. –§—É–Ω–∫—Ü–∏—é count_freq —è –ø—Ä–æ–≤–µ—Ä—è–ª –±–∞–∑–æ–≤—ã–º–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏ –∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–Ω–∏—è–º–∏ —Å–ª–æ–≤. top_n —è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª –ø—Ä–∏ –ø–æ–º–æ—â–∏ –±–∞–∑–æ–≤—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π —Å–∏–º–≤–æ–ª–æ–≤, –æ–¥–Ω–∞–∫–æ –æ—Ç–¥–µ–ª—å–Ω–æ –≤—ã–Ω–µ—Å —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É.
![text_pytest](https://github.com/user-attachments/assets/856e50cf-e88a-4881-94bb-8baab31cc681)
–¢–∞–∫ –∂–µ, —è –ø—Ä–æ–≤–µ—Ä–∏–ª –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∫–æ–¥–∞ –ø—Ä–∏ –ø–æ–º–æ—â–∏ black:
![text_black](https://github.com/user-attachments/assets/dc49cbb7-7265-4352-b15a-073c1931f3bf)

### –ó–∞–¥–∞–Ω–∏–µ B
```python
import pytest
import csv
import json
from pathlib import Path
from src.lab05.json_csv import json_to_csv, csv_to_json

def test_json_to_csv_roundtrip(tmp_path: Path):
    # –±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ json
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert rows[0]["name"] == "Alice"
    assert rows[0]["age"] == "22"
    assert rows[1]["name"] == "Bob"
    assert rows[1]["age"] == "25"


def test_csv_to_json_roundtrip(tmp_path: Path):
    # –±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ csv
    src = tmp_path / "people.csv"
    dst = tmp_path / "people.json"

    # —Å–æ–∑–¥–∞–µ–º CSV —Ñ–∞–π–ª
    with src.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()
        writer.writerows(
            [
                {"name": "Alice", "age": "22"},
                {"name": "Bob", "age": "25"},
            ]
        )

    csv_to_json(str(src), str(dst))
    with dst.open(encoding="utf-8") as f:
        data = json.load(f)

    assert len(data) == 2
    assert data[0]["name"] == "Alice"
    assert data[0]["age"] == "22"
    assert data[1]["name"] == "Bob"
    assert data[1]["age"] == "25"


def test_json_to_csv_empty_json(tmp_path: Path):
    # —Ç–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç–æ–≥–æ json
    src = tmp_path / "empty.json"
    dst = tmp_path / "output.csv"
    src.write_text("[]", encoding="utf-8")

    with pytest.raises(ValueError, match="–ü—É—Å—Ç–æ–π JSON –∏–ª–∏ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞"):
        json_to_csv(str(src), str(dst))


def test_csv_to_json_empty_csv(tmp_path: Path):
    # —Ç–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç–æ–≥–æ csv
    src = tmp_path / "empty.csv"
    dst = tmp_path / "output.json"

    # c–æ–∑–¥–∞–µ–º CSV —Ç–æ–ª—å–∫–æ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
    with src.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()

    with pytest.raises(ValueError):
        csv_to_json(str(src), str(dst))


def test_json_to_csv_file_not_found(tmp_path: Path, capsys):
    # —Ç–µ—Å—Ç –Ω–∞ FileNotFoudError
    src = tmp_path / "nonexistent.json"
    dst = tmp_path / "output.csv"

    json_to_csv(str(src), str(dst))

    captured = capsys.readouterr()
    assert "FileNotFoundError" in captured.out
```
–í —Å–ª—É—á–∞–µ —Å —Ç–µ—Å—Ç–æ–º –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π, —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö —Å —Ñ–∞–π–ª–∞–º–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å tmp_path, —á—Ç–æ–±—ã –Ω–µ –≥–æ—Ä–æ–¥–∏—Ç—å –Ω–µ–Ω—É–∂–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ \data. –Ø –Ω–∞—á–∞–ª —Å –±–∞–∑–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ json –≤ csv, —Ç–∞–º —è –ø—Ä–æ–≤–µ—Ä–∏–ª —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –≤ —è—á–µ–π–∫–∞—Ö, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫. –ó–∞—Ç–µ–º –ø–æ—Ö–æ–∂–∏–π –±–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ csv –≤ json. –î–∞–ª–µ–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—ã–ª–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–±–æ—Ç—É —Ñ—É–Ω–∫—Ü–∏–π —Å –ø—É—Å—Ç—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏. –ó–∞–≤–µ—Ä—à–∞–µ—Ç —Ç–µ—Å—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—à–∏–±–∫–∏ FileNotFoundError. (–ø—Ä–æ–≤–µ—Ä–∫–∞ black –≤ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ)
![json_text_black](https://github.com/user-attachments/assets/31bfb3d2-d4c7-4416-89ee-76d611d8a17a)
